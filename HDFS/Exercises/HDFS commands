
# HDFS commands

http://localhost:8080

> hdfs dfs  - Check all the HDFS commands

> sbin/start-all.sh : To start all the Hadoop services

 > jps :  To check list of active services  and their port numbers

 > hdfs dfs -ls / : Prints all the directories present in HDFS

 > dfs -mkdir <folder name> : Create a new directory in HDFS

 > hdfs dfs -touchz <file_path> : Creates an empty file

 > hdfs dfs -copyFromLocal <local file path> <dest(present on hdfs)> : To copy the files/folders from local file system to HDFS store

 > hdfs dfs -cat <path> : Prints the file contents


 > hdfs dfs -copyToLocal <<srcfile(on hdfs)> <local file dest> : To copy files/folders from HDFS store to the local file system

 > hdfs dfs -cp <src(on hdfs)> <dest(on hdfs)> :  Copy files with in HDFS

 > hdfs dfs -rmr <filename/directoryName> : Deletes a file from HDFS recursively

 > hdfs dfs -du <dirName> : Gives the size of each file in the directory

 > hdfs dfs -setrep -R -w 6 <filename/directoryName> : Change the replication factor of file/folder inside HDFS. By default it is 3.


Create a path of directories - 

hdfs dfs -mkdir -p /this/is/a/new/directory - create a path of directories
hdfs dfs -ls  - Only HIVE directories (user created directories) 
hdfs dfs -ls / - lists enture directory structure
wget http://media.sundog-soft.com/hadoop/ml-100k/u.data - downloading the data in to local 
hdfs dfs -put source_hadoop/word_count.txt /dest_hadoop - copy the file from one directory to another
hadoop fs -ls -R - recursively display the directories, subdirectories and files
hadoop fs -copyFromLocal u.data ml-100k/u.data - copy a file from local to HDFS


Using help - 

> hadoop fs –help ls

Get file sizes in readable format - 
> hadoop fs –ls –S –h /public/hdfs_dataset 

Search for files with in a directory - 
> hadoop fs –ls –R /public | grep order 

Create a new directory -
> hadoop fs –mkdir /user/hadoop/hdfs_new

Recursively remove a directory - 
> hadoop fs –rm -R /user/hadoop/hdfs_new

Remove an empty directory - 
> hadoop fs –rmdir –-ignore-fail-on-non-empty  /user/hadoop/hdfs_new

Previewing the files - 

Display entire file - 
> hadoop fs -help cat

Display starting of file -
> hadoop fs –cat /public/txt_files/*|more 

Display last 1 KB of a large file - 
> hadoop fs –help tail
> hadoop fs –tail /public/txt_files/large_file.txt


Getting metadata of files in a HDFS folder - 
> hdfs fsck /user/data/hdfs_data –files 
> hdfs fsck /user/data/hdfs_data –files -blocks 
> hdfs fsck /user/data/hdfs_data –files -blocks -locations 

Get the size in human readable format - 

Summary of the size occupied, size remaining, % of size occupied etc..,
> hdfs dfs –df –h /user/data/hdfs_data

Disk usage of directories and all the subdirectories inside the main directory
> hdfs dfs –du –h /user/data/hdfs_data 

Only main directory disk usage summary
hdfs dfs –du -s –h /user/data/hdfs_data 

Change the replication factor of a main folder on run-time - 
hdfs dfs –Ddfs.replication=3 –put /user/data/hdfs_data/large_file.txt /user/hdfs_main


# HDFS Exercises - 

Create h1b directory under your user space /user/YOUR_OS_USERNAME
Copy Directory /public/h1b/h1b_kaggle to /user/YOUR_OS_USERNAME/h1b
Preview last 1 KB of Data
Get the size of the data set for the newly copied directory.
Get metadata of the directory copied /user/YOUR_OS_USERNAME/h1b/h1b_kaggle



  


